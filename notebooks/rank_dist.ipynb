{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rank_dist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNSNNp1oEGSqZFfyeiSMvEc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alanjeffares/Simplex/blob/main/notebooks/rank_dist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/alanjeffares/Simplex.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaGHsss8Ahsh",
        "outputId": "8f5cca6d-b982-47e8-fe35-e6a344b9881b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Simplex'...\n",
            "remote: Enumerating objects: 617, done.\u001b[K\n",
            "remote: Counting objects: 100% (617/617), done.\u001b[K\n",
            "remote: Compressing objects: 100% (413/413), done.\u001b[K\n",
            "remote: Total 617 (delta 361), reused 396 (delta 153), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (617/617), 1.17 MiB | 11.34 MiB/s, done.\n",
            "Resolving deltas: 100% (361/361), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum\n",
        "!pip install pytorch_influence_functions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QtSSHMKoCNU",
        "outputId": "67ef296e-b112-488c-c0e1-297bb765b4e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting captum\n",
            "  Downloading captum-0.4.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 38.0 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 122 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 133 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 143 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 153 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 163 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 174 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 184 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 194 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 204 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 215 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 225 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 235 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 245 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 256 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 266 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 276 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 286 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 296 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 307 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 317 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 327 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 337 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 348 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 358 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 368 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 378 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 389 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 399 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 409 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 419 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 430 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 440 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 450 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 460 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 471 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 481 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 491 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 501 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 512 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 522 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 532 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 542 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 552 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 563 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 573 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 583 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 593 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 604 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 614 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 624 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 634 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 645 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 655 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 665 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 675 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 686 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 696 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 706 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 716 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 727 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 737 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 747 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 757 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 768 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 778 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 788 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 798 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 808 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 819 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 829 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 839 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 849 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 860 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 870 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 880 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 890 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 901 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 911 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 921 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 931 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 942 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 952 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 962 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 972 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 983 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 993 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4 MB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->captum) (3.10.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum) (1.15.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.4.1\n",
            "Collecting pytorch_influence_functions\n",
            "  Downloading pytorch_influence_functions-0.1.1.tar.gz (18 kB)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_influence_functions) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_influence_functions) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->pytorch_influence_functions) (3.10.0.2)\n",
            "Building wheels for collected packages: pytorch-influence-functions\n",
            "  Building wheel for pytorch-influence-functions (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-influence-functions: filename=pytorch_influence_functions-0.1.1-py3-none-any.whl size=14966 sha256=b06232ff956ca85c966b952c8e5eaea484d584b09df76a944475ee59801d366d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/35/b0/f1ac8c66296a2fded385cfcd5d993fdd4c5ff7f33d24bf2fa7\n",
            "Successfully built pytorch-influence-functions\n",
            "Installing collected packages: pytorch-influence-functions\n",
            "Successfully installed pytorch-influence-functions-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Simplex/\n",
        "import explainers\n",
        "from explainers.simplex import Simplex\n",
        "import models\n",
        "from models.image_recognition import MnistClassifier\n",
        "from utils.schedulers import ExponentialScheduler\n",
        "from experiments.mnist import load_mnist\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYwGfV-Ms-BA",
        "outputId": "02dd4e9c-c410-4652-b9a2-607bf996ca39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Simplex\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys, importlib\n",
        "# %cd Simplex/\n",
        "# importlib.reload(sys.modules['models.image_recognition'])\n",
        "# from models.image_recognition import MnistClassifier\n",
        "# %cd ../\n"
      ],
      "metadata": {
        "id": "HiYPRKEQrW-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparams\n",
        "corpus_size = 100\n",
        "cv_ls = list(range(10))"
      ],
      "metadata": {
        "id": "an9U-_2JYLFo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the code\n",
        "%cd Simplex/\n",
        "for cv in cv_ls:\n",
        "  !python -m experiments.mnist -experiment \"approximation_quality\" -cv $cv -corpus_size $corpus_size\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOACcrMIs2_y",
        "outputId": "3839c0d3-7c33-4b8f-bdfa-b5fe9a1a095f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Simplex\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Welcome in the approximation quality experiment for MNIST. \n",
            "Settings: random_seed = 42 ; cv = 0.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the model. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Test set: Avg. loss: 2.3168, Accuracy: 664/10000(7%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.259823\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.266444\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.130428\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.129363\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.918430\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.712793\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.774907\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.565635\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.662826\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.928538\n",
            "\n",
            "Test set: Avg. loss: 0.3929, Accuracy: 9023/10000(90%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.709593\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.446521\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.656988\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.631452\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.763422\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.687409\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.580497\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.746190\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.519453\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.557454\n",
            "\n",
            "Test set: Avg. loss: 0.3372, Accuracy: 9189/10000(92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.476175\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.679901\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.535079\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.542535\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.454445\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.581501\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.695667\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.819342\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.641839\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.526374\n",
            "\n",
            "Test set: Avg. loss: 0.3020, Accuracy: 9257/10000(93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.560663\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.517434\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.654958\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.724994\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.508724\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.479152\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.374204\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.478143\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.665543\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.620293\n",
            "\n",
            "Test set: Avg. loss: 0.3144, Accuracy: 9284/10000(93%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.464113\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.488997\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.751942\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.527265\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.467394\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.641744\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.565141\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.402221\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.567825\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.522233\n",
            "\n",
            "Test set: Avg. loss: 0.3023, Accuracy: 9259/10000(93%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.646270\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.695540\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.481686\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.473928\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.522764\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.568080\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.655778\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.562699\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.482197\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.744842\n",
            "\n",
            "Test set: Avg. loss: 0.2865, Accuracy: 9267/10000(93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.424704\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.500688\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.448019\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.532639\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.543562\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.285054\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.534205\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.578686\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.476890\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.415234\n",
            "\n",
            "Test set: Avg. loss: 0.2845, Accuracy: 9304/10000(93%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.609362\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.609646\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.450340\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.510752\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.520669\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.412867\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.444878\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.647097\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.480740\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.593597\n",
            "\n",
            "Test set: Avg. loss: 0.2827, Accuracy: 9331/10000(93%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.511812\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.483305\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.369752\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.524650\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.532500\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.325332\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.563157\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.523087\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.471596\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.455705\n",
            "\n",
            "Test set: Avg. loss: 0.2892, Accuracy: 9285/10000(93%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.386495\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.409631\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.466161\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.422993\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.507472\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.638815\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.473423\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.534137\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.651488\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.730506\n",
            "\n",
            "Test set: Avg. loss: 0.2862, Accuracy: 9305/10000(93%)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the explainers. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "------------------------------n_keep = 3------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.29e+03 ; Regulator: 76.5 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.76e+03 ; Regulator: 41.9 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.33e+03 ; Regulator: 19.6 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.29e+03 ; Regulator: 5.36 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.36e+03 ; Regulator: 0.624 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv0_n3.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv0_n3.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv0_n3.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv0.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv0.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.95.\n",
            "nn_uniform latent r2: 0.85 ; output r2 = 0.89.\n",
            "nn_dist latent r2: 0.86 ; output r2 = 0.9.\n",
            "------------------------------n_keep = 5------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.29e+03 ; Regulator: 63.6 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.76e+03 ; Regulator: 27.9 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.33e+03 ; Regulator: 10.1 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.24e+03 ; Regulator: 2.31 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.22e+03 ; Regulator: 0.375 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv0_n5.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv0_n5.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv0_n5.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv0.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv0.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.84 ; output r2 = 0.88.\n",
            "nn_dist latent r2: 0.85 ; output r2 = 0.89.\n",
            "------------------------------n_keep = 10------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.29e+03 ; Regulator: 41.2 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.76e+03 ; Regulator: 13.3 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.34e+03 ; Regulator: 4.49 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.23e+03 ; Regulator: 1.27 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.2e+03 ; Regulator: 0.266 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv0_n10.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv0_n10.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv0_n10.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv0.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv0.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.8 ; output r2 = 0.85.\n",
            "nn_dist latent r2: 0.83 ; output r2 = 0.87.\n",
            "------------------------------n_keep = 20------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.29e+03 ; Regulator: 22.4 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.77e+03 ; Regulator: 6.7 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.34e+03 ; Regulator: 2.41 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.23e+03 ; Regulator: 0.81 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.2e+03 ; Regulator: 0.198 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv0_n20.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv0_n20.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv0_n20.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv0.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv0.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.67 ; output r2 = 0.72.\n",
            "nn_dist latent r2: 0.75 ; output r2 = 0.8.\n",
            "------------------------------n_keep = 50------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.29e+03 ; Regulator: 9.5 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.77e+03 ; Regulator: 2.96 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.34e+03 ; Regulator: 1.11 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.23e+03 ; Regulator: 0.4 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.2e+03 ; Regulator: 0.108 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv0_n50.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv0_n50.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv0_n50.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv0.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv0.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.39 ; output r2 = 0.45.\n",
            "nn_dist latent r2: 0.54 ; output r2 = 0.6.\n",
            "Saving representer decomposition in /content/Simplex/experiments/results/mnist/quality/representer_cv0.pkl.\n",
            "representer output r2 = -15.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Welcome in the approximation quality experiment for MNIST. \n",
            "Settings: random_seed = 42 ; cv = 1.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the model. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Test set: Avg. loss: 2.3152, Accuracy: 1094/10000(11%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.333745\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.212021\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.704261\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.985151\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.935901\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.961578\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.669261\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.568960\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.666989\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.797590\n",
            "\n",
            "Test set: Avg. loss: 0.3802, Accuracy: 9076/10000(91%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.574012\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.610944\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.677154\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.746079\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.504412\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.430922\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.680096\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.478631\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.631769\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.476171\n",
            "\n",
            "Test set: Avg. loss: 0.3275, Accuracy: 9241/10000(92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.618953\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.675949\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.639942\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.469912\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.345188\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.615073\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.530963\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.522591\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.554372\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.657232\n",
            "\n",
            "Test set: Avg. loss: 0.2925, Accuracy: 9313/10000(93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.550958\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.370398\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.600140\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.617683\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.570436\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.321844\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.486822\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.429963\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.446761\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.571153\n",
            "\n",
            "Test set: Avg. loss: 0.2899, Accuracy: 9354/10000(94%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.744082\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.393933\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.483392\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.739216\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.425908\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.677188\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.516124\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.531214\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.611631\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.500873\n",
            "\n",
            "Test set: Avg. loss: 0.2982, Accuracy: 9296/10000(93%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.570796\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.483880\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.564619\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.351653\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.666400\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.590353\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.547281\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.646564\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.561189\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.454893\n",
            "\n",
            "Test set: Avg. loss: 0.2859, Accuracy: 9306/10000(93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.535824\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.532967\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.375048\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.375157\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.382585\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.357475\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.662864\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.392521\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.554671\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.338794\n",
            "\n",
            "Test set: Avg. loss: 0.2884, Accuracy: 9321/10000(93%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.675352\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.538081\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.503926\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.479071\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.550181\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.415646\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.568201\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.508691\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.351960\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.663082\n",
            "\n",
            "Test set: Avg. loss: 0.2742, Accuracy: 9371/10000(94%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.353796\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.404306\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.457609\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.534355\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.442575\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.497110\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.527260\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.437979\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.524593\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.446645\n",
            "\n",
            "Test set: Avg. loss: 0.2599, Accuracy: 9393/10000(94%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.605842\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.500473\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.592748\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.522657\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.491896\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.486192\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.590602\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.419192\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.467009\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.512043\n",
            "\n",
            "Test set: Avg. loss: 0.2590, Accuracy: 9392/10000(94%)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the explainers. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "------------------------------n_keep = 3------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.12e+03 ; Regulator: 76.9 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.49e+03 ; Regulator: 43.5 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.06e+03 ; Regulator: 19.1 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.01e+03 ; Regulator: 5.85 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.1e+03 ; Regulator: 0.83 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv1_n3.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv1_n3.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv1_n3.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv1.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv1.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.94 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.87 ; output r2 = 0.91.\n",
            "nn_dist latent r2: 0.88 ; output r2 = 0.92.\n",
            "------------------------------n_keep = 5------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.12e+03 ; Regulator: 64.3 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.49e+03 ; Regulator: 29.3 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.06e+03 ; Regulator: 10.5 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 972 ; Regulator: 2.54 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 954 ; Regulator: 0.406 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv1_n5.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv1_n5.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv1_n5.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv1.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv1.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.95 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.86 ; output r2 = 0.9.\n",
            "nn_dist latent r2: 0.87 ; output r2 = 0.91.\n",
            "------------------------------n_keep = 10------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.12e+03 ; Regulator: 42.9 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.49e+03 ; Regulator: 14.8 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.06e+03 ; Regulator: 5 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 959 ; Regulator: 1.39 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 925 ; Regulator: 0.291 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv1_n10.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv1_n10.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv1_n10.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv1.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv1.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.95 ; output r2 = 0.98.\n",
            "nn_uniform latent r2: 0.79 ; output r2 = 0.85.\n",
            "nn_dist latent r2: 0.84 ; output r2 = 0.88.\n",
            "------------------------------n_keep = 20------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.13e+03 ; Regulator: 22.7 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.5e+03 ; Regulator: 7.04 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.06e+03 ; Regulator: 2.59 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 958 ; Regulator: 0.867 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 922 ; Regulator: 0.212 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv1_n20.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv1_n20.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv1_n20.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv1.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv1.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.95 ; output r2 = 0.98.\n",
            "nn_uniform latent r2: 0.66 ; output r2 = 0.73.\n",
            "nn_dist latent r2: 0.75 ; output r2 = 0.81.\n",
            "------------------------------n_keep = 50------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.13e+03 ; Regulator: 9.52 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.5e+03 ; Regulator: 3.07 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.07e+03 ; Regulator: 1.18 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 960 ; Regulator: 0.428 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 923 ; Regulator: 0.116 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv1_n50.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv1_n50.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv1_n50.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv1.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv1.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.95 ; output r2 = 0.98.\n",
            "nn_uniform latent r2: 0.39 ; output r2 = 0.44.\n",
            "nn_dist latent r2: 0.55 ; output r2 = 0.6.\n",
            "Saving representer decomposition in /content/Simplex/experiments/results/mnist/quality/representer_cv1.pkl.\n",
            "representer output r2 = -23.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Welcome in the approximation quality experiment for MNIST. \n",
            "Settings: random_seed = 42 ; cv = 2.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the model. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Test set: Avg. loss: 2.3200, Accuracy: 792/10000(8%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.386671\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.178877\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.412541\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.000690\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.841501\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.952091\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.606103\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.701215\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.763806\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.551484\n",
            "\n",
            "Test set: Avg. loss: 0.4189, Accuracy: 9036/10000(90%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.804916\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.594313\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.806451\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.617215\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.573516\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.728379\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.423104\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.644976\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.569781\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.532173\n",
            "\n",
            "Test set: Avg. loss: 0.3323, Accuracy: 9111/10000(91%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.547731\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.499230\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.768181\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.633649\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.580952\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.513392\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.817317\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.509106\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.550480\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.626412\n",
            "\n",
            "Test set: Avg. loss: 0.3171, Accuracy: 9263/10000(93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.549332\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.658535\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.510589\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.648911\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.508214\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.593624\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.540782\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.767194\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.914848\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.598160\n",
            "\n",
            "Test set: Avg. loss: 0.3120, Accuracy: 9236/10000(92%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.571933\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.712802\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.472063\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.556626\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.572974\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.398420\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.573696\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.675001\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.530697\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.733952\n",
            "\n",
            "Test set: Avg. loss: 0.3009, Accuracy: 9294/10000(93%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.758469\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.608649\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.439035\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.528970\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.570174\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.569552\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.480867\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.506583\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.451037\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.481587\n",
            "\n",
            "Test set: Avg. loss: 0.2917, Accuracy: 9311/10000(93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.499618\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.453208\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.505332\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.453847\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.715808\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.550310\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.711253\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.389554\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.520820\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.571070\n",
            "\n",
            "Test set: Avg. loss: 0.2797, Accuracy: 9309/10000(93%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.414439\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.576413\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.532717\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.428823\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.601498\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.675808\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.603347\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.651527\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.480313\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.498303\n",
            "\n",
            "Test set: Avg. loss: 0.2830, Accuracy: 9272/10000(93%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.441403\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.583467\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.494864\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.492277\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.429457\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.494533\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.422812\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.676062\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.384704\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.675706\n",
            "\n",
            "Test set: Avg. loss: 0.2801, Accuracy: 9308/10000(93%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.560296\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.483057\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.602897\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.590646\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.489577\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.542373\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.585082\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.599197\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.399239\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.482353\n",
            "\n",
            "Test set: Avg. loss: 0.2946, Accuracy: 9257/10000(93%)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the explainers. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "------------------------------n_keep = 3------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.55e+03 ; Regulator: 77.9 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.89e+03 ; Regulator: 43.1 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.44e+03 ; Regulator: 19.5 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.4e+03 ; Regulator: 5.83 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.48e+03 ; Regulator: 0.646 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv2_n3.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv2_n3.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv2_n3.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv2.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv2.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.91 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.85 ; output r2 = 0.9.\n",
            "nn_dist latent r2: 0.85 ; output r2 = 0.91.\n",
            "------------------------------n_keep = 5------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.55e+03 ; Regulator: 65.8 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.89e+03 ; Regulator: 28.9 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.44e+03 ; Regulator: 10.4 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.35e+03 ; Regulator: 2.38 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.33e+03 ; Regulator: 0.377 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv2_n5.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv2_n5.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv2_n5.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv2.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv2.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.84 ; output r2 = 0.89.\n",
            "nn_dist latent r2: 0.85 ; output r2 = 0.9.\n",
            "------------------------------n_keep = 10------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.55e+03 ; Regulator: 43 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.89e+03 ; Regulator: 13.9 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.45e+03 ; Regulator: 4.44 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.34e+03 ; Regulator: 1.21 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.3e+03 ; Regulator: 0.256 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv2_n10.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv2_n10.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv2_n10.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv2.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv2.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.79 ; output r2 = 0.85.\n",
            "nn_dist latent r2: 0.82 ; output r2 = 0.87.\n",
            "------------------------------n_keep = 20------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.55e+03 ; Regulator: 22.2 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.89e+03 ; Regulator: 6.46 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.45e+03 ; Regulator: 2.27 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.34e+03 ; Regulator: 0.744 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.3e+03 ; Regulator: 0.184 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv2_n20.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv2_n20.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv2_n20.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv2.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv2.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.68 ; output r2 = 0.75.\n",
            "nn_dist latent r2: 0.75 ; output r2 = 0.81.\n",
            "------------------------------n_keep = 50------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.56e+03 ; Regulator: 9.19 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.9e+03 ; Regulator: 2.81 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.45e+03 ; Regulator: 1.02 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.34e+03 ; Regulator: 0.362 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.3e+03 ; Regulator: 0.0988 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv2_n50.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv2_n50.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv2_n50.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv2.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv2.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.39 ; output r2 = 0.46.\n",
            "nn_dist latent r2: 0.54 ; output r2 = 0.61.\n",
            "Saving representer decomposition in /content/Simplex/experiments/results/mnist/quality/representer_cv2.pkl.\n",
            "representer output r2 = -40.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Welcome in the approximation quality experiment for MNIST. \n",
            "Settings: random_seed = 42 ; cv = 3.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the model. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Test set: Avg. loss: 2.3087, Accuracy: 959/10000(10%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.319785\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.179907\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.561263\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.048454\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.815147\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.966368\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.855324\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.717830\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.793455\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.673105\n",
            "\n",
            "Test set: Avg. loss: 0.3953, Accuracy: 8948/10000(89%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.559097\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.563433\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.560183\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.596751\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.761025\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.665453\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.484176\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.561935\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.421659\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.683747\n",
            "\n",
            "Test set: Avg. loss: 0.3100, Accuracy: 9250/10000(92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.337253\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.501057\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.644166\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.812015\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.586033\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.486728\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.361706\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.548215\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.714615\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.439281\n",
            "\n",
            "Test set: Avg. loss: 0.2877, Accuracy: 9318/10000(93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.510424\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.713316\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.573663\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.450172\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.654131\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.520379\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.497901\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.537954\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.514108\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.471486\n",
            "\n",
            "Test set: Avg. loss: 0.3004, Accuracy: 9262/10000(93%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.481106\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.534896\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.730945\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.529108\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.493167\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.431415\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.516089\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.449855\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.575757\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.589691\n",
            "\n",
            "Test set: Avg. loss: 0.2957, Accuracy: 9290/10000(93%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.554219\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.493170\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.438888\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.550781\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.683260\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.508731\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.643362\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.528552\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.613305\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.545209\n",
            "\n",
            "Test set: Avg. loss: 0.2748, Accuracy: 9335/10000(93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.422040\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.674627\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.578409\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.599421\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.511068\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.544508\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.729088\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.406427\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.530882\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.478815\n",
            "\n",
            "Test set: Avg. loss: 0.2770, Accuracy: 9364/10000(94%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.529544\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.601384\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.645354\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.414402\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.422525\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.578872\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.454854\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.505214\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.409566\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.525575\n",
            "\n",
            "Test set: Avg. loss: 0.2850, Accuracy: 9311/10000(93%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.497511\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.516254\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.423319\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.392207\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.498001\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.518548\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.480037\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.651446\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.534232\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.536626\n",
            "\n",
            "Test set: Avg. loss: 0.2786, Accuracy: 9349/10000(93%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.613704\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.688258\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.382683\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.387789\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.595640\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.502306\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.452723\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.514596\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.610150\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.350364\n",
            "\n",
            "Test set: Avg. loss: 0.2767, Accuracy: 9373/10000(94%)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the explainers. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "------------------------------n_keep = 3------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.1e+03 ; Regulator: 76.2 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.31e+03 ; Regulator: 44.9 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.01e+03 ; Regulator: 21.4 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.01e+03 ; Regulator: 5.75 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.09e+03 ; Regulator: 0.551 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv3_n3.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv3_n3.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv3_n3.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv3.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv3.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.87 ; output r2 = 0.9.\n",
            "nn_dist latent r2: 0.87 ; output r2 = 0.91.\n",
            "------------------------------n_keep = 5------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.1e+03 ; Regulator: 62.9 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.32e+03 ; Regulator: 30.1 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.01e+03 ; Regulator: 11.6 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 957 ; Regulator: 2.47 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 949 ; Regulator: 0.355 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv3_n5.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv3_n5.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv3_n5.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv3.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv3.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.86 ; output r2 = 0.9.\n",
            "nn_dist latent r2: 0.87 ; output r2 = 0.9.\n",
            "------------------------------n_keep = 10------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.1e+03 ; Regulator: 40.7 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.32e+03 ; Regulator: 14.3 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.01e+03 ; Regulator: 4.88 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 934 ; Regulator: 1.34 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 910 ; Regulator: 0.252 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv3_n10.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv3_n10.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv3_n10.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv3.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv3.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.82 ; output r2 = 0.86.\n",
            "nn_dist latent r2: 0.85 ; output r2 = 0.88.\n",
            "------------------------------n_keep = 20------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.1e+03 ; Regulator: 22 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.32e+03 ; Regulator: 7.04 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.01e+03 ; Regulator: 2.62 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 932 ; Regulator: 0.863 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 904 ; Regulator: 0.191 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv3_n20.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv3_n20.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv3_n20.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv3.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv3.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.69 ; output r2 = 0.75.\n",
            "nn_dist latent r2: 0.77 ; output r2 = 0.82.\n",
            "------------------------------n_keep = 50------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.1e+03 ; Regulator: 9.72 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.32e+03 ; Regulator: 3.21 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.02e+03 ; Regulator: 1.24 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 935 ; Regulator: 0.443 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 905 ; Regulator: 0.109 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv3_n50.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv3_n50.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv3_n50.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv3.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv3.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.38 ; output r2 = 0.43.\n",
            "nn_dist latent r2: 0.56 ; output r2 = 0.6.\n",
            "Saving representer decomposition in /content/Simplex/experiments/results/mnist/quality/representer_cv3.pkl.\n",
            "representer output r2 = -79.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Welcome in the approximation quality experiment for MNIST. \n",
            "Settings: random_seed = 42 ; cv = 4.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the model. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Test set: Avg. loss: 2.2973, Accuracy: 1334/10000(13%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.299339\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.192123\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.219774\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.975428\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.035416\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.789419\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.739378\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.567680\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.657532\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.636791\n",
            "\n",
            "Test set: Avg. loss: 0.3889, Accuracy: 9078/10000(91%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.623270\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.560592\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.473210\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.625972\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.728602\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.516705\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.684281\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.389327\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.550145\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.520922\n",
            "\n",
            "Test set: Avg. loss: 0.3100, Accuracy: 9262/10000(93%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.521974\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.526862\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.404491\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.614260\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.572835\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.551483\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.568939\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.676925\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.610214\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.721653\n",
            "\n",
            "Test set: Avg. loss: 0.3126, Accuracy: 9155/10000(92%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.293842\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.451546\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.500908\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.767435\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.562158\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.538110\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.618242\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.662511\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.488256\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.472561\n",
            "\n",
            "Test set: Avg. loss: 0.2938, Accuracy: 9336/10000(93%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.573309\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.548145\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.626743\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.616061\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.673762\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.427359\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.610920\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.523815\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.772718\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.500305\n",
            "\n",
            "Test set: Avg. loss: 0.2856, Accuracy: 9333/10000(93%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.721826\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.556542\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.957100\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.455154\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.365253\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.359354\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.483990\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.616003\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.452645\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.527809\n",
            "\n",
            "Test set: Avg. loss: 0.2835, Accuracy: 9348/10000(93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.631441\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.541894\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.572198\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.437178\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.605107\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.669834\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.430561\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.680399\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.512000\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.538720\n",
            "\n",
            "Test set: Avg. loss: 0.2656, Accuracy: 9347/10000(93%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.580160\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.427041\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.375219\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.443946\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.355437\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.624128\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.495183\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.409928\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.568757\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.573321\n",
            "\n",
            "Test set: Avg. loss: 0.2816, Accuracy: 9307/10000(93%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.599422\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.736429\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.630356\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.348167\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.540081\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.473994\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.745955\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.331325\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.491872\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.590734\n",
            "\n",
            "Test set: Avg. loss: 0.2715, Accuracy: 9338/10000(93%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.397094\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.672437\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.411701\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.540790\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.414807\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.488189\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.434639\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.536256\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.470758\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.503737\n",
            "\n",
            "Test set: Avg. loss: 0.2621, Accuracy: 9380/10000(94%)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the explainers. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "------------------------------n_keep = 3------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.85e+03 ; Regulator: 77.4 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.44e+03 ; Regulator: 42.7 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.04e+03 ; Regulator: 20.9 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.02e+03 ; Regulator: 6.38 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.11e+03 ; Regulator: 0.741 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv4_n3.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv4_n3.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv4_n3.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv4.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv4.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.85 ; output r2 = 0.9.\n",
            "nn_dist latent r2: 0.86 ; output r2 = 0.91.\n",
            "------------------------------n_keep = 5------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.85e+03 ; Regulator: 65 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.44e+03 ; Regulator: 28.6 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.04e+03 ; Regulator: 10.8 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 960 ; Regulator: 2.57 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 949 ; Regulator: 0.385 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv4_n5.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv4_n5.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv4_n5.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv4.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv4.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.94 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.84 ; output r2 = 0.89.\n",
            "nn_dist latent r2: 0.85 ; output r2 = 0.9.\n",
            "------------------------------n_keep = 10------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.85e+03 ; Regulator: 42.7 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.44e+03 ; Regulator: 13.5 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.04e+03 ; Regulator: 4.62 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 941 ; Regulator: 1.3 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 912 ; Regulator: 0.271 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv4_n10.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv4_n10.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv4_n10.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv4.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv4.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.94 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.79 ; output r2 = 0.85.\n",
            "nn_dist latent r2: 0.82 ; output r2 = 0.88.\n",
            "------------------------------n_keep = 20------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.86e+03 ; Regulator: 22.2 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.44e+03 ; Regulator: 6.6 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.04e+03 ; Regulator: 2.42 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 943 ; Regulator: 0.809 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 910 ; Regulator: 0.198 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv4_n20.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv4_n20.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv4_n20.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv4.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv4.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.94 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.69 ; output r2 = 0.75.\n",
            "nn_dist latent r2: 0.76 ; output r2 = 0.82.\n",
            "------------------------------n_keep = 50------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.86e+03 ; Regulator: 9.5 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.45e+03 ; Regulator: 2.97 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.04e+03 ; Regulator: 1.13 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 945 ; Regulator: 0.405 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 912 ; Regulator: 0.109 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv4_n50.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv4_n50.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv4_n50.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv4.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv4.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.94 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.4 ; output r2 = 0.46.\n",
            "nn_dist latent r2: 0.56 ; output r2 = 0.62.\n",
            "Saving representer decomposition in /content/Simplex/experiments/results/mnist/quality/representer_cv4.pkl.\n",
            "representer output r2 = -27.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Welcome in the approximation quality experiment for MNIST. \n",
            "Settings: random_seed = 42 ; cv = 5.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the model. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Test set: Avg. loss: 2.3033, Accuracy: 1038/10000(10%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.330379\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.166229\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.456225\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.047014\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.819281\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.737764\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.703453\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.736787\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.566056\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.667596\n",
            "\n",
            "Test set: Avg. loss: 0.3757, Accuracy: 9038/10000(90%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.707743\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.522313\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.746800\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.603780\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.677420\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.471429\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.630992\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.645986\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.521786\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.510860\n",
            "\n",
            "Test set: Avg. loss: 0.3064, Accuracy: 9223/10000(92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.524718\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.438929\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.552615\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.421370\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.631683\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.501493\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.444943\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.444297\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.533531\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.651080\n",
            "\n",
            "Test set: Avg. loss: 0.2797, Accuracy: 9330/10000(93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.558795\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.534035\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.519427\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.521820\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.480986\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.520850\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.557841\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.659521\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.478654\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.553768\n",
            "\n",
            "Test set: Avg. loss: 0.2786, Accuracy: 9337/10000(93%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.494974\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.324909\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.341202\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.573716\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.483915\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.645587\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.490255\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.502137\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.489670\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.600885\n",
            "\n",
            "Test set: Avg. loss: 0.2703, Accuracy: 9354/10000(94%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.378217\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.528812\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.561780\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.512232\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.546602\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.462782\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.719358\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.693976\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.510679\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.450113\n",
            "\n",
            "Test set: Avg. loss: 0.2881, Accuracy: 9320/10000(93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.609869\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.541476\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.600195\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.509371\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.558957\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.535102\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.431249\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.443595\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.573350\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.538865\n",
            "\n",
            "Test set: Avg. loss: 0.2797, Accuracy: 9353/10000(94%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.591757\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.409567\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.521010\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.654859\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.642930\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.434897\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.598465\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.405601\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.553496\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.483151\n",
            "\n",
            "Test set: Avg. loss: 0.2716, Accuracy: 9406/10000(94%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.445093\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.472244\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.579834\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.702057\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.494706\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.553552\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.347660\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.503266\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.481978\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.545643\n",
            "\n",
            "Test set: Avg. loss: 0.2642, Accuracy: 9380/10000(94%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.662518\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.565091\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.519843\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.633262\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.607347\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.401190\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.506508\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.610845\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.403497\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.448955\n",
            "\n",
            "Test set: Avg. loss: 0.2814, Accuracy: 9310/10000(93%)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the explainers. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "------------------------------n_keep = 3------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.83e+03 ; Regulator: 75.6 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.52e+03 ; Regulator: 41.4 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.16e+03 ; Regulator: 19.9 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.14e+03 ; Regulator: 5.75 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.23e+03 ; Regulator: 0.584 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv5_n3.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv5_n3.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv5_n3.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv5.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv5.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.85 ; output r2 = 0.9.\n",
            "nn_dist latent r2: 0.86 ; output r2 = 0.9.\n",
            "------------------------------n_keep = 5------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.83e+03 ; Regulator: 62.4 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.52e+03 ; Regulator: 26.9 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.16e+03 ; Regulator: 10 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.09e+03 ; Regulator: 2.4 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.07e+03 ; Regulator: 0.37 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv5_n5.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv5_n5.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv5_n5.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv5.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv5.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.85 ; output r2 = 0.9.\n",
            "nn_dist latent r2: 0.87 ; output r2 = 0.91.\n",
            "------------------------------n_keep = 10------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.83e+03 ; Regulator: 39.8 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.53e+03 ; Regulator: 13 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.16e+03 ; Regulator: 4.5 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.07e+03 ; Regulator: 1.28 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.04e+03 ; Regulator: 0.264 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv5_n10.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv5_n10.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv5_n10.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv5.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv5.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.8 ; output r2 = 0.85.\n",
            "nn_dist latent r2: 0.83 ; output r2 = 0.88.\n",
            "------------------------------n_keep = 20------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.83e+03 ; Regulator: 21.5 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.53e+03 ; Regulator: 6.64 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.16e+03 ; Regulator: 2.47 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.07e+03 ; Regulator: 0.831 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.03e+03 ; Regulator: 0.198 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv5_n20.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv5_n20.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv5_n20.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv5.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv5.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.68 ; output r2 = 0.75.\n",
            "nn_dist latent r2: 0.76 ; output r2 = 0.81.\n",
            "------------------------------n_keep = 50------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.84e+03 ; Regulator: 9.56 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.53e+03 ; Regulator: 3.05 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.17e+03 ; Regulator: 1.16 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.07e+03 ; Regulator: 0.415 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.03e+03 ; Regulator: 0.108 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv5_n50.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv5_n50.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv5_n50.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv5.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv5.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.38 ; output r2 = 0.45.\n",
            "nn_dist latent r2: 0.54 ; output r2 = 0.6.\n",
            "Saving representer decomposition in /content/Simplex/experiments/results/mnist/quality/representer_cv5.pkl.\n",
            "representer output r2 = -4.6.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Welcome in the approximation quality experiment for MNIST. \n",
            "Settings: random_seed = 42 ; cv = 6.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the model. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Test set: Avg. loss: 2.3150, Accuracy: 981/10000(10%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.269807\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.102009\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.118371\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.836491\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.025393\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.734811\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.603151\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.495640\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.695869\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.805183\n",
            "\n",
            "Test set: Avg. loss: 0.3902, Accuracy: 8988/10000(90%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.713867\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.507290\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.889303\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.605012\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.611253\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.659240\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.600190\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.520150\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.748797\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.883670\n",
            "\n",
            "Test set: Avg. loss: 0.3363, Accuracy: 9162/10000(92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.744448\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.612639\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.687828\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.834705\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.640837\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.494703\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.574817\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.607697\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.844748\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.850709\n",
            "\n",
            "Test set: Avg. loss: 0.3083, Accuracy: 9262/10000(93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.617614\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.464037\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.455400\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.452324\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.841045\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.658100\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.597467\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.390423\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.559448\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.451626\n",
            "\n",
            "Test set: Avg. loss: 0.3013, Accuracy: 9266/10000(93%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.483000\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.557327\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.565780\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.641304\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.558236\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.624799\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.612268\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.654876\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.584931\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.719167\n",
            "\n",
            "Test set: Avg. loss: 0.2953, Accuracy: 9315/10000(93%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.615844\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.610584\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.545827\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.682398\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.383479\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.563953\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.524442\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.370021\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.521205\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.541325\n",
            "\n",
            "Test set: Avg. loss: 0.2892, Accuracy: 9300/10000(93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.530250\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.484567\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.685945\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.495769\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.805238\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.549547\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.463673\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.396882\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.463551\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.419068\n",
            "\n",
            "Test set: Avg. loss: 0.2787, Accuracy: 9353/10000(94%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.584438\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.599341\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.558600\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.591007\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.443297\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.406333\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.409135\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.355789\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.694470\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.618588\n",
            "\n",
            "Test set: Avg. loss: 0.2787, Accuracy: 9378/10000(94%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.629075\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.382792\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.529235\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.374744\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.463787\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.636358\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.561026\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.495905\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.641010\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.538972\n",
            "\n",
            "Test set: Avg. loss: 0.2838, Accuracy: 9340/10000(93%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.621602\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.616395\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.377655\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.563254\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.440459\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.435226\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.354304\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.569481\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.542714\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.713985\n",
            "\n",
            "Test set: Avg. loss: 0.2628, Accuracy: 9382/10000(94%)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the explainers. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "------------------------------n_keep = 3------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.84e+03 ; Regulator: 75.8 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.38e+03 ; Regulator: 40.9 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.03e+03 ; Regulator: 19.9 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 999 ; Regulator: 6.02 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.09e+03 ; Regulator: 0.655 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv6_n3.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv6_n3.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv6_n3.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv6.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv6.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.87 ; output r2 = 0.91.\n",
            "nn_dist latent r2: 0.88 ; output r2 = 0.92.\n",
            "------------------------------n_keep = 5------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.84e+03 ; Regulator: 62.7 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.38e+03 ; Regulator: 26.8 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.02e+03 ; Regulator: 10.2 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 946 ; Regulator: 2.45 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 928 ; Regulator: 0.39 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv6_n5.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv6_n5.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv6_n5.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv6.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv6.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.94 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.87 ; output r2 = 0.91.\n",
            "nn_dist latent r2: 0.88 ; output r2 = 0.92.\n",
            "------------------------------n_keep = 10------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.84e+03 ; Regulator: 40.6 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.38e+03 ; Regulator: 13 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.03e+03 ; Regulator: 4.57 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 930 ; Regulator: 1.34 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 899 ; Regulator: 0.279 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv6_n10.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv6_n10.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv6_n10.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv6.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv6.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.94 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.8 ; output r2 = 0.85.\n",
            "nn_dist latent r2: 0.85 ; output r2 = 0.88.\n",
            "------------------------------n_keep = 20------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.85e+03 ; Regulator: 21.3 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.39e+03 ; Regulator: 6.46 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.03e+03 ; Regulator: 2.48 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 932 ; Regulator: 0.862 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 898 ; Regulator: 0.207 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv6_n20.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv6_n20.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv6_n20.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv6.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv6.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.94 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.67 ; output r2 = 0.73.\n",
            "nn_dist latent r2: 0.77 ; output r2 = 0.81.\n",
            "------------------------------n_keep = 50------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 3.85e+03 ; Regulator: 9.45 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.39e+03 ; Regulator: 2.97 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.03e+03 ; Regulator: 1.17 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 935 ; Regulator: 0.432 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 899 ; Regulator: 0.114 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv6_n50.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv6_n50.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv6_n50.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv6.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv6.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.94 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.36 ; output r2 = 0.41.\n",
            "nn_dist latent r2: 0.54 ; output r2 = 0.58.\n",
            "Saving representer decomposition in /content/Simplex/experiments/results/mnist/quality/representer_cv6.pkl.\n",
            "representer output r2 = -11.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Welcome in the approximation quality experiment for MNIST. \n",
            "Settings: random_seed = 42 ; cv = 7.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the model. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Test set: Avg. loss: 2.3113, Accuracy: 1038/10000(10%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305287\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.189394\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.561558\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.818262\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.707878\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.672141\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.711187\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.715859\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.453471\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.735590\n",
            "\n",
            "Test set: Avg. loss: 0.3788, Accuracy: 9083/10000(91%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.650264\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.503281\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.507139\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.594354\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.599860\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.631641\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.652953\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.492958\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.523890\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.531075\n",
            "\n",
            "Test set: Avg. loss: 0.3133, Accuracy: 9211/10000(92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.396423\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.534600\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.752411\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.444342\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.661482\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.521795\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.668358\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.383065\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.737836\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.742681\n",
            "\n",
            "Test set: Avg. loss: 0.2912, Accuracy: 9280/10000(93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.715248\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.504858\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.454404\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.447753\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.490013\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.534122\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.436983\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.564297\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.588130\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.412545\n",
            "\n",
            "Test set: Avg. loss: 0.2851, Accuracy: 9265/10000(93%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.598836\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.696672\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.631757\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.533261\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.454100\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.530026\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.444674\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.523766\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.583019\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.618164\n",
            "\n",
            "Test set: Avg. loss: 0.2793, Accuracy: 9353/10000(94%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.361061\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.480816\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.386151\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.605645\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.440403\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.604130\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.349190\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.675784\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.413207\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.684782\n",
            "\n",
            "Test set: Avg. loss: 0.2735, Accuracy: 9399/10000(94%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.393675\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.552168\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.532024\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.610425\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.331942\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.390461\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.544341\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.587872\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.602402\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.429032\n",
            "\n",
            "Test set: Avg. loss: 0.2738, Accuracy: 9387/10000(94%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.448973\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.446103\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.637514\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.477818\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.505003\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.329756\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.491549\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.450480\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.576483\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.404316\n",
            "\n",
            "Test set: Avg. loss: 0.2756, Accuracy: 9342/10000(93%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.443040\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.385726\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.372747\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.651498\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.570799\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.750505\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.448050\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.620064\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.440386\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.569150\n",
            "\n",
            "Test set: Avg. loss: 0.2684, Accuracy: 9373/10000(94%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.457803\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.438751\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.439643\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.493539\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.325599\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.420030\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.475727\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.581332\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.605204\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.501698\n",
            "\n",
            "Test set: Avg. loss: 0.2771, Accuracy: 9332/10000(93%)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the explainers. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "------------------------------n_keep = 3------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.22e+03 ; Regulator: 75.9 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.57e+03 ; Regulator: 38.6 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.16e+03 ; Regulator: 16.6 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.11e+03 ; Regulator: 4.69 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.16e+03 ; Regulator: 0.606 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv7_n3.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv7_n3.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv7_n3.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv7.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv7.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.85 ; output r2 = 0.9.\n",
            "nn_dist latent r2: 0.86 ; output r2 = 0.91.\n",
            "------------------------------n_keep = 5------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.22e+03 ; Regulator: 62.9 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.57e+03 ; Regulator: 25.4 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.16e+03 ; Regulator: 9.3 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.08e+03 ; Regulator: 2.24 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.06e+03 ; Regulator: 0.365 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv7_n5.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv7_n5.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv7_n5.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv7.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv7.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.85 ; output r2 = 0.89.\n",
            "nn_dist latent r2: 0.86 ; output r2 = 0.9.\n",
            "------------------------------n_keep = 10------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.22e+03 ; Regulator: 41.1 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.58e+03 ; Regulator: 12.6 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.16e+03 ; Regulator: 4.25 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.06e+03 ; Regulator: 1.25 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.03e+03 ; Regulator: 0.262 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv7_n10.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv7_n10.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv7_n10.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv7.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv7.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.8 ; output r2 = 0.86.\n",
            "nn_dist latent r2: 0.84 ; output r2 = 0.89.\n",
            "------------------------------n_keep = 20------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.22e+03 ; Regulator: 21.7 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.58e+03 ; Regulator: 6.41 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.17e+03 ; Regulator: 2.33 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.06e+03 ; Regulator: 0.801 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.03e+03 ; Regulator: 0.194 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv7_n20.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv7_n20.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv7_n20.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv7.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv7.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.67 ; output r2 = 0.74.\n",
            "nn_dist latent r2: 0.75 ; output r2 = 0.81.\n",
            "------------------------------n_keep = 50------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.22e+03 ; Regulator: 9.31 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.58e+03 ; Regulator: 2.9 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.17e+03 ; Regulator: 1.09 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.07e+03 ; Regulator: 0.399 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.03e+03 ; Regulator: 0.106 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv7_n50.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv7_n50.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv7_n50.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv7.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv7.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.97.\n",
            "nn_uniform latent r2: 0.37 ; output r2 = 0.45.\n",
            "nn_dist latent r2: 0.52 ; output r2 = 0.59.\n",
            "Saving representer decomposition in /content/Simplex/experiments/results/mnist/quality/representer_cv7.pkl.\n",
            "representer output r2 = -19.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Welcome in the approximation quality experiment for MNIST. \n",
            "Settings: random_seed = 42 ; cv = 8.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the model. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Test set: Avg. loss: 2.3065, Accuracy: 1141/10000(11%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.353902\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.201265\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.670079\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.226141\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.824277\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.523358\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.618280\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.905685\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.750352\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.795194\n",
            "\n",
            "Test set: Avg. loss: 0.3896, Accuracy: 9041/10000(90%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.519673\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.561387\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.643693\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.557540\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.623755\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.637908\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.714249\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.578854\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.585166\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.579958\n",
            "\n",
            "Test set: Avg. loss: 0.3344, Accuracy: 9183/10000(92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.571320\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.645397\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.764246\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.751494\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.721127\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.532409\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.561416\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.474039\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.563225\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.638125\n",
            "\n",
            "Test set: Avg. loss: 0.3253, Accuracy: 9251/10000(93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.518369\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.640167\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.630287\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.589146\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.617953\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.462423\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.486233\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.627639\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.470310\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.518029\n",
            "\n",
            "Test set: Avg. loss: 0.3225, Accuracy: 9171/10000(92%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.603558\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.533523\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.472261\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.485083\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.405967\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.586281\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.390942\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.628440\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.637601\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.842931\n",
            "\n",
            "Test set: Avg. loss: 0.3030, Accuracy: 9268/10000(93%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.538008\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.558346\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.439998\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.506022\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.595935\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.502342\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.490322\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.616659\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.583473\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.462803\n",
            "\n",
            "Test set: Avg. loss: 0.2964, Accuracy: 9268/10000(93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.465469\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.454103\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.627266\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.549735\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.517193\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.509536\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.654263\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.447805\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.652811\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.545816\n",
            "\n",
            "Test set: Avg. loss: 0.2953, Accuracy: 9279/10000(93%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.402961\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.496556\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.551853\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.628466\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.515986\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.581674\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.493220\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.509542\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.412119\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.609723\n",
            "\n",
            "Test set: Avg. loss: 0.2788, Accuracy: 9325/10000(93%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.574036\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.659248\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.620095\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.595230\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.528808\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.596890\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.417543\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.439980\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.502685\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.380989\n",
            "\n",
            "Test set: Avg. loss: 0.2852, Accuracy: 9305/10000(93%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.411273\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.574890\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.470390\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.549491\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.543544\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.601600\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.508707\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.681349\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.567542\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.649459\n",
            "\n",
            "Test set: Avg. loss: 0.2906, Accuracy: 9333/10000(93%)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the explainers. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "------------------------------n_keep = 3------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.87e+03 ; Regulator: 75.8 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 2.05e+03 ; Regulator: 40.8 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.61e+03 ; Regulator: 19.3 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.56e+03 ; Regulator: 5.78 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.64e+03 ; Regulator: 0.613 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv8_n3.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv8_n3.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv8_n3.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv8.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv8.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.91 ; output r2 = 0.95.\n",
            "nn_uniform latent r2: 0.83 ; output r2 = 0.89.\n",
            "nn_dist latent r2: 0.84 ; output r2 = 0.89.\n",
            "------------------------------n_keep = 5------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.87e+03 ; Regulator: 63 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 2.05e+03 ; Regulator: 26.6 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.61e+03 ; Regulator: 10.3 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.52e+03 ; Regulator: 2.48 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.5e+03 ; Regulator: 0.383 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv8_n5.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv8_n5.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv8_n5.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv8.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv8.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.91 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.83 ; output r2 = 0.88.\n",
            "nn_dist latent r2: 0.84 ; output r2 = 0.89.\n",
            "------------------------------n_keep = 10------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.87e+03 ; Regulator: 40.9 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 2.06e+03 ; Regulator: 13 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.61e+03 ; Regulator: 4.48 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.49e+03 ; Regulator: 1.26 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.45e+03 ; Regulator: 0.263 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv8_n10.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv8_n10.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv8_n10.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv8.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv8.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.77 ; output r2 = 0.82.\n",
            "nn_dist latent r2: 0.8 ; output r2 = 0.85.\n",
            "------------------------------n_keep = 20------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.87e+03 ; Regulator: 22.3 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 2.06e+03 ; Regulator: 6.64 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.61e+03 ; Regulator: 2.43 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.49e+03 ; Regulator: 0.803 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.45e+03 ; Regulator: 0.193 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv8_n20.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv8_n20.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv8_n20.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv8.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv8.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.64 ; output r2 = 0.71.\n",
            "nn_dist latent r2: 0.72 ; output r2 = 0.78.\n",
            "------------------------------n_keep = 50------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.88e+03 ; Regulator: 9.46 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 2.06e+03 ; Regulator: 2.96 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.61e+03 ; Regulator: 1.12 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.49e+03 ; Regulator: 0.397 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.45e+03 ; Regulator: 0.105 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv8_n50.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv8_n50.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv8_n50.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv8.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv8.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.35 ; output r2 = 0.42.\n",
            "nn_dist latent r2: 0.5 ; output r2 = 0.57.\n",
            "Saving representer decomposition in /content/Simplex/experiments/results/mnist/quality/representer_cv8.pkl.\n",
            "representer output r2 = -15.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Welcome in the approximation quality experiment for MNIST. \n",
            "Settings: random_seed = 42 ; cv = 9.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the model. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Test set: Avg. loss: 2.3127, Accuracy: 948/10000(9%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.310105\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.219002\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.417354\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.027566\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.728300\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.952558\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.795457\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.652054\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.687727\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.646709\n",
            "\n",
            "Test set: Avg. loss: 0.3965, Accuracy: 9053/10000(91%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.588945\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.576023\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.697274\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.549928\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.566990\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.459721\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.626171\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.822574\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.591613\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.613394\n",
            "\n",
            "Test set: Avg. loss: 0.3278, Accuracy: 9215/10000(92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.530115\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.955576\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.726352\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.561883\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.640094\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.765880\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.487888\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.692839\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.386769\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.507242\n",
            "\n",
            "Test set: Avg. loss: 0.3164, Accuracy: 9257/10000(93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.790495\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.724242\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.452677\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.719655\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.614563\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.571696\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.547906\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.453781\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.417752\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.824813\n",
            "\n",
            "Test set: Avg. loss: 0.3063, Accuracy: 9214/10000(92%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.433978\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.427859\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.613447\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.650577\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.448800\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.552114\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.641483\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.519389\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.613802\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.504922\n",
            "\n",
            "Test set: Avg. loss: 0.3054, Accuracy: 9275/10000(93%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.582219\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.394155\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.798836\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.517612\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.512587\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.604552\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.475739\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.571026\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.525803\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.446365\n",
            "\n",
            "Test set: Avg. loss: 0.2816, Accuracy: 9337/10000(93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.580601\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.393764\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.673172\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.454411\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.572147\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.474720\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.491825\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.385011\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.399735\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.399123\n",
            "\n",
            "Test set: Avg. loss: 0.3031, Accuracy: 9264/10000(93%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.460184\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.663809\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.638268\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.577910\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.453715\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.621604\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.819115\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.486430\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.429644\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.598430\n",
            "\n",
            "Test set: Avg. loss: 0.2984, Accuracy: 9278/10000(93%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.443218\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.634872\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.591386\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.416859\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.756799\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.557021\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.629054\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.591682\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.418947\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.722997\n",
            "\n",
            "Test set: Avg. loss: 0.2815, Accuracy: 9324/10000(93%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.838492\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.441190\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.514590\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.433346\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.562933\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.557843\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.488612\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.627872\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.463885\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.403614\n",
            "\n",
            "Test set: Avg. loss: 0.2707, Accuracy: 9330/10000(93%)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Now fitting the explainers. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "------------------------------n_keep = 3------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.52e+03 ; Regulator: 77.8 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.82e+03 ; Regulator: 43.6 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.37e+03 ; Regulator: 20.9 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.32e+03 ; Regulator: 6 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.4e+03 ; Regulator: 0.723 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv9_n3.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv9_n3.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv9_n3.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv9.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv9.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.92 ; output r2 = 0.95.\n",
            "nn_uniform latent r2: 0.87 ; output r2 = 0.89.\n",
            "nn_dist latent r2: 0.87 ; output r2 = 0.9.\n",
            "------------------------------n_keep = 5------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.52e+03 ; Regulator: 65.4 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.83e+03 ; Regulator: 29.5 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.36e+03 ; Regulator: 11 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.27e+03 ; Regulator: 2.56 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.25e+03 ; Regulator: 0.412 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv9_n5.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv9_n5.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv9_n5.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv9.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv9.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.85 ; output r2 = 0.88.\n",
            "nn_dist latent r2: 0.87 ; output r2 = 0.89.\n",
            "------------------------------n_keep = 10------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.52e+03 ; Regulator: 42.2 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.83e+03 ; Regulator: 14 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.37e+03 ; Regulator: 4.83 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.26e+03 ; Regulator: 1.4 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.23e+03 ; Regulator: 0.291 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv9_n10.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv9_n10.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv9_n10.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv9.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv9.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.83 ; output r2 = 0.86.\n",
            "nn_dist latent r2: 0.85 ; output r2 = 0.88.\n",
            "------------------------------n_keep = 20------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.53e+03 ; Regulator: 21.8 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.83e+03 ; Regulator: 6.57 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.37e+03 ; Regulator: 2.44 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.26e+03 ; Regulator: 0.836 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.22e+03 ; Regulator: 0.207 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv9_n20.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv9_n20.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv9_n20.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv9.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv9.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.73 ; output r2 = 0.77.\n",
            "nn_dist latent r2: 0.79 ; output r2 = 0.83.\n",
            "------------------------------n_keep = 50------------------------------\n",
            "Weight Fitting Epoch: 2000/10000 ; Error: 4.53e+03 ; Regulator: 9.29 ; Reg Factor: 0.398\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 1.83e+03 ; Regulator: 2.92 ; Reg Factor: 1.58\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 1.37e+03 ; Regulator: 1.12 ; Reg Factor: 6.31\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 1.26e+03 ; Regulator: 0.41 ; Reg Factor: 25.1\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 1.22e+03 ; Regulator: 0.112 ; Reg Factor: 99.9\n",
            "Saving simplex decomposition in /content/Simplex/experiments/results/mnist/quality/simplex_cv9_n50.pkl.\n",
            "Saving nn_uniform decomposition in /content/Simplex/experiments/results/mnist/quality/nn_uniform_cv9_n50.pkl.\n",
            "Saving nn_dist decomposition in /content/Simplex/experiments/results/mnist/quality/nn_dist_cv9_n50.pkl.\n",
            "Saving corpus data in /content/Simplex/experiments/results/mnist/quality/corpus_data_cv9.pkl.\n",
            "Saving test data in /content/Simplex/experiments/results/mnist/quality/test_data_cv9.pkl.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Results. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "simplex latent r2: 0.93 ; output r2 = 0.96.\n",
            "nn_uniform latent r2: 0.43 ; output r2 = 0.46.\n",
            "nn_dist latent r2: 0.59 ; output r2 = 0.62.\n",
            "Saving representer decomposition in /content/Simplex/experiments/results/mnist/quality/representer_cv9.pkl.\n",
            "representer output r2 = -20.\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_bar(dists: torch.tensor, selected_idx: torch.tensor):\n",
        "  vals, _ = torch.sort(dists)\n",
        "  plt.figure(figsize=(20,5))\n",
        "  barlist = plt.bar(list(range(0,100)), vals.squeeze(0).cpu().numpy(), width=1)\n",
        "  for idx in selected_idx:\n",
        "    barlist[idx.item()].set_color('r')\n",
        "  plt.show()\n",
        "\n",
        "# corpus_data_ls = pickle.load( open( f\"/content/Simplex/experiments/results/mnist/quality/corpus_data_cv{cv}.pkl\", \"rb\" ) )\n",
        "# [corpus_latent_reps, corpus_probas, corpus_true_classes] = corpus_data_ls\n",
        "\n",
        "# test_data_ls = pickle.load( open( f\"/content/Simplex/experiments/results/mnist/quality/test_data_cv{cv}.pkl\", \"rb\" ) )\n",
        "# [test_latent_reps, test_target] = test_data_ls\n",
        "\n",
        "def load_run(cv: int):\n",
        "  simplex = pickle.load( open( f\"/content/Simplex/experiments/results/mnist/quality/simplex_cv{cv}_n5.pkl\", \"rb\" ) )\n",
        "\n",
        "  # load saved model\n",
        "  classifier = MnistClassifier()\n",
        "  classifier.load_state_dict(torch.load(f'/content/Simplex/experiments/results/mnist/quality/model_cv{cv}.pth'))\n",
        "  classifier.to('cuda')\n",
        "  classifier.eval()\n",
        "  return simplex, classifier\n",
        "\n",
        "simplex, classifier = load_run(0)"
      ],
      "metadata": {
        "id": "fTmpWCPzxfRP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for test example i which examples in the corpus have weight > 0.01\n",
        "i = 0\n",
        "test_i_lrg_corpus_weights = simplex.weights[i] > 0.01"
      ],
      "metadata": {
        "id": "KXX_2YKg1IWl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the latent state of the test example\n",
        "test_example = simplex.test_examples[i].unsqueeze(0)\n",
        "test_example_latent_true = classifier.latent_representation(test_example)\n",
        "\n",
        "# this is equivelent and returns the same vector\n",
        "test_example_latent_true = simplex.test_latent_reps[i].unsqueeze(0)\n",
        "\n",
        "# now grab the approximation of that vector in the corpus convex hull\n",
        "test_latent_approx = simplex.latent_approx()\n",
        "test_example_latent_approx = test_latent_approx[i].unsqueeze(0)\n",
        "\n",
        "# distance between true latent and approx latent of test example\n",
        "approx_dist = torch.sum((test_example_latent_approx - test_example_latent_true)**2)**0.5\n",
        "print('Distance between latent approx and latent true:', approx_dist.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3myAzfeXXPVf",
        "outputId": "e7c9d771-545a-47c4-a9cb-59178700d62b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance between latent approx and latent true: 5.1901535987854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate distance from test latent approximation to the highly weighted corpus examples\n",
        "dists = torch.cdist(test_example_latent_approx, simplex.corpus_latent_reps)\n",
        "_, ranks = torch.unique(dists, sorted=True, return_inverse=True)\n",
        "sorted_ranks, _ = ranks[0,test_i_lrg_corpus_weights].sort()\n",
        "\n",
        "\n",
        "print('Latent test representation distance to each corpus representation is calcuated and ordered (low to high).')\n",
        "print('Then the rank of the corpus examples used in the reconstruction is extracted.\\n')\n",
        "print('Approximate latent representation of the test example:', sorted_ranks)\n",
        "vals, idxs = torch.sort(dists)\n",
        "weights = simplex.weights[i][idxs[0]][test_i_lrg_corpus_weights[idxs[0]]]\n",
        "print('With corresponding weight values: ', weights)\n",
        "plot_bar(dists, ranks[0,test_i_lrg_corpus_weights])\n",
        "\n",
        "\n",
        "# calculate distance from test latent ground truth to the highly weighted corpus examples\n",
        "dists = torch.cdist(test_example_latent_true, simplex.corpus_latent_reps)\n",
        "_, ranks = torch.unique(dists, sorted=True, return_inverse=True)\n",
        "sorted_ranks, _ = ranks[0,test_i_lrg_corpus_weights].sort()\n",
        "\n",
        "print('\\nTrue latent representation of the test example:', sorted_ranks)\n",
        "vals, idxs = torch.sort(dists)\n",
        "weights = simplex.weights[i][idxs[0]][test_i_lrg_corpus_weights[idxs[0]]]\n",
        "print('With corresponding weight values: ', weights)\n",
        "\n",
        "plot_bar(dists, ranks[0,test_i_lrg_corpus_weights])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "pzKT3KIXsML8",
        "outputId": "942d5ee2-5a30-4048-aa14-35074c17dae2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latent test representation distance to each corpus representation is calcuated and ordered (low to high).\n",
            "Then the rank of the corpus examples used in the reconstruction is extracted.\n",
            "\n",
            "Approximate latent representation of the test example: tensor([ 1,  2, 11, 68], device='cuda:0')\n",
            "With corresponding weight values:  tensor([0.2900, 0.4344, 0.0556, 0.2125], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "True latent representation of the test example: tensor([ 1,  2,  7, 54], device='cuda:0')\n",
            "With corresponding weight values:  tensor([0.2900, 0.4344, 0.0556, 0.2125], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T8b9CidE_dr2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def reconstruction_rank_dist(i, simplex):\n",
        "  \"\"\"\n",
        "  Of the latent corpus examples used to approximate the test example with\n",
        "  weight > 0.01, find and return their rank distance to the original latent test\n",
        "  example of the 1000 total corpus examples and also return their associated \n",
        "  weights.\n",
        "  \"\"\"\n",
        "  test_i_lrg_corpus_weights = simplex.weights[i] > 0.01\n",
        "\n",
        "  # this is equivelent and returns the same vector\n",
        "  test_example_latent_true = simplex.test_latent_reps[i].unsqueeze(0)\n",
        "\n",
        "  # now grab the approximation of that vector in the corpus convex hull\n",
        "  test_latent_approx = simplex.latent_approx()\n",
        "  test_example_latent_approx = test_latent_approx[i].unsqueeze(0)\n",
        "\n",
        "  # calculate distance from test latent approximation to the highly weighted corpus examples\n",
        "  dists = torch.cdist(test_example_latent_approx, simplex.corpus_latent_reps)\n",
        "  _, ranks = torch.unique(dists, sorted=True, return_inverse=True)\n",
        "  sorted_ranks, _ = ranks[0,test_i_lrg_corpus_weights].sort()\n",
        "\n",
        "  # calculate distance from test latent ground truth to the highly weighted corpus examples\n",
        "  dists = torch.cdist(test_example_latent_true, simplex.corpus_latent_reps)\n",
        "  _, ranks = torch.unique(dists, sorted=True, return_inverse=True)\n",
        "  sorted_ranks, _ = ranks[0,test_i_lrg_corpus_weights].sort()\n",
        "\n",
        "  vals, idxs = torch.sort(dists)\n",
        "  weights = simplex.weights[i][idxs[0]][test_i_lrg_corpus_weights[idxs[0]]]\n",
        "  return sorted_ranks, weights\n",
        "\n",
        "def calculate_for_test(simplex):\n",
        "  N_TEST = 100\n",
        "  weighted_ranks = torch.empty(0, device='cuda')\n",
        "  all_ranks = torch.empty(0, device='cuda')\n",
        "  for i in range(N_TEST):\n",
        "    sorted_ranks, weights = reconstruction_rank_dist(i, simplex)\n",
        "    all_ranks = torch.cat([all_ranks, sorted_ranks])\n",
        "    weighted_rank_i = sorted_ranks * weights\n",
        "    weighted_ranks = torch.cat([weighted_ranks,weighted_rank_i])\n",
        "  return weighted_ranks, all_ranks"
      ],
      "metadata": {
        "id": "AzNLGOjnnCSv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_test = 100\n",
        "avg_weighted_ranks = []\n",
        "avg_avg_ranks = []\n",
        "all_ranks_full = []\n",
        "for cv in cv_ls:\n",
        "  simplex, classifier = load_run(cv)\n",
        "  weighted_ranks, all_ranks = calculate_for_test(simplex)\n",
        "  weighted_rank = weighted_ranks.sum()/n_test\n",
        "  avg_rank = torch.mean(all_ranks)\n",
        "  print('Weighted rank:', weighted_rank.item())\n",
        "  print('Raw average rank: ', avg_rank.item())\n",
        "  avg_weighted_ranks.append(weighted_rank.item())\n",
        "  avg_avg_ranks.append(avg_rank.item())\n",
        "  all_ranks_full.extend(all_ranks.cpu().tolist())\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjGL2rAMnCV7",
        "outputId": "6075e0c3-c18f-4cfc-f2a4-76cdbf9191f8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted rank: 4.600566387176514\n",
            "Raw average rank:  9.072639465332031\n",
            "Weighted rank: 4.696116924285889\n",
            "Raw average rank:  8.63990306854248\n",
            "Weighted rank: 4.634210586547852\n",
            "Raw average rank:  8.198564529418945\n",
            "Weighted rank: 4.291878700256348\n",
            "Raw average rank:  6.9666666984558105\n",
            "Weighted rank: 4.871251106262207\n",
            "Raw average rank:  8.108433723449707\n",
            "Weighted rank: 4.389005184173584\n",
            "Raw average rank:  7.814644813537598\n",
            "Weighted rank: 4.754767894744873\n",
            "Raw average rank:  8.380281448364258\n",
            "Weighted rank: 4.415623188018799\n",
            "Raw average rank:  8.540201187133789\n",
            "Weighted rank: 4.449130535125732\n",
            "Raw average rank:  8.580645561218262\n",
            "Weighted rank: 3.538151741027832\n",
            "Raw average rank:  5.783783912658691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7qi-DkdZ0JUG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(avg_weighted_ranks))\n",
        "print(np.std(avg_weighted_ranks))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnULl3XLlJnP",
        "outputId": "9b21cad3-4bae-4655-bc2e-716ca76af533"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.464070224761963\n",
            "0.3531155690509162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(avg_avg_ranks))\n",
        "print(np.std(avg_avg_ranks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UMgXOs8lM1_",
        "outputId": "f72baa88-55b5-4d80-cd86-35f2997c6c12"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.008576440811158\n",
            "0.9163956636958143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Weighted rank:', weighted_ranks.sum()/n_test)\n",
        "print('Raw average rank: ', torch.mean(all_ranks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVlYn_ddnCYf",
        "outputId": "c24bf7ed-6784-4946-f164-26ed080e22e2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted rank: tensor(3.5382, device='cuda:0')\n",
            "Raw average rank:  tensor(5.7838, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(all_ranks > 20).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o5bFBJQrSGd",
        "outputId": "1a7c30b7-7e5b-4d45-b973-c3e6b1942f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(63, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.hist(all_ranks_full, bins=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "lB4LxBuIqagY",
        "outputId": "175a4ca3-e6f0-4d4e-d9fe-a41b845fb60e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oWivW48vnCaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OMrh-3h02GsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate distance from test latent approximation to the highly weighted corpus examples\n",
        "dists = torch.cdist(test_example_latent, simplex.corpus_latent_reps)\n",
        "sorted, indices = dists.sort()\n",
        "indices[0,test_i_lrg_corpus_weights]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPBWJpUd4LzV",
        "outputId": "c26cdf5e-f067-4eb9-d7bc-733b99d9b123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([748, 653, 494, 670, 573], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate distance from test latent ground truth to the highly weighted corpus examples\n",
        "dists = torch.cdist(test_example_latent_true, simplex.corpus_latent_reps)\n",
        "sorted, indices = dists.sort()\n",
        "indices[0,test_i_lrg_corpus_weights]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxOEVYFp5zpZ",
        "outputId": "6cff69fc-c841-4433-b5e5-2cb8f0d5680b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([826, 785, 676], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# distance from approx and true latent states of test example to obs j from the corpus\n",
        "j = 6\n",
        "print(torch.sum((test_example_latent_approx - simplex.corpus_latent_reps[j,:])**2)**0.5)\n",
        "print(torch.sum((test_example_latent_true - simplex.corpus_latent_reps[j,:])**2)**0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36-vYnNE63m9",
        "outputId": "5b01162d-10d1-4fd1-9e04-1aab50810845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(17.9488, device='cuda:0')\n",
            "tensor(18.9352, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simplex.corpus_latent_reps[0,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yd20rkT7MAv",
        "outputId": "884a72b4-f283-4d85-a07c-1cfc16401264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.4077, 0.0000, 2.3789, 0.0000, 0.0000, 5.6503, 1.4715, 3.7833, 0.3766,\n",
              "        0.3691, 0.0000, 0.0000, 0.6946, 0.0000, 0.0000, 0.0000, 3.0126, 0.0000,\n",
              "        0.0000, 0.7745, 3.6202, 7.7748, 0.0000, 4.7042, 7.2362, 0.0000, 0.0000,\n",
              "        0.0000, 2.1782, 0.0000, 3.4734, 0.3607, 0.0000, 0.0000, 5.8450, 0.0000,\n",
              "        0.0000, 2.7952, 7.6346, 2.3497, 4.1248, 1.6305, 0.0000, 0.0000, 0.0000,\n",
              "        2.3954, 8.2084, 7.5170, 0.0000, 2.2113], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJZKHL7H5zrZ",
        "outputId": "b2a4091e-4005-4d2e-80b4-3148626b541a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([463, 928, 118], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e4x0QMXqIrUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit explainer logic"
      ],
      "metadata": {
        "id": "lKNht6d4Ivgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters \n",
        "random_seed = 42\n",
        "cv = 0\n",
        "path = f'/content/Simplex/experiments/results/mnist/quality/model_cv{cv}.pth'\n",
        "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "corpus_size = 100\n",
        "test_size = 1\n",
        "n_epoch = 1000\n",
        "train_only = False\n",
        "reg_factor_init = 0.1\n",
        "reg_factor_final = 100\n",
        "n_keep = 5\n",
        "\n",
        "# main logic\n",
        "torch.random.manual_seed(random_seed + cv)\n",
        "explainers = []\n",
        "\n",
        "# Load model:\n",
        "classifier = MnistClassifier()\n",
        "classifier.load_state_dict(torch.load(path))\n",
        "classifier.to(device)\n",
        "classifier.eval()\n",
        "\n",
        "# Load data:\n",
        "corpus_loader = load_mnist(corpus_size, train=True)\n",
        "test_loader = load_mnist(test_size, train=train_only)\n",
        "corpus_examples = enumerate(corpus_loader)\n",
        "test_examples = enumerate(test_loader)\n",
        "batch_id_test, (test_data, test_targets) = next(test_examples)\n",
        "batch_id_corpus, (corpus_data, corpus_target) = next(corpus_examples)\n",
        "corpus_data = corpus_data.to(device).detach()\n",
        "test_data = test_data.to(device).detach()\n",
        "corpus_latent_reps = classifier.latent_representation(corpus_data).detach()\n",
        "corpus_probas = classifier.probabilities(corpus_data).detach()\n",
        "corpus_true_classes = torch.zeros(corpus_probas.shape, device=device)\n",
        "corpus_true_classes[torch.arange(corpus_size), corpus_target] = 1\n",
        "test_latent_reps = classifier.latent_representation(test_data).detach()\n",
        "\n",
        "# Fit SimplEx:\n",
        "reg_factor_scheduler = ExponentialScheduler(reg_factor_init, reg_factor_final, n_epoch)\n",
        "simplex = Simplex(corpus_examples=corpus_data,\n",
        "                  corpus_latent_reps=corpus_latent_reps)\n",
        "# simplex.fit(test_examples=test_data,\n",
        "#             test_latent_reps=test_latent_reps,\n",
        "#             n_epoch=n_epoch, reg_factor=reg_factor_init, n_keep=n_keep,\n",
        "#             reg_factor_scheduler=reg_factor_scheduler)\n",
        "simplex.fit_optimal(test_examples=test_data,\n",
        "            test_latent_reps=test_latent_reps)"
      ],
      "metadata": {
        "id": "uEDP0WSeIpW7"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, importlib\n",
        "%cd Simplex/\n",
        "importlib.reload(sys.modules['explainers.simplex'])\n",
        "from explainers.simplex import Simplex\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJFBgqsdS8Bc",
        "outputId": "c107dba2-ab22-4593-cdb2-ff1eb9d3cfd8"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Simplex\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import Lars\n",
        "\n",
        "\n",
        "def fit_optimal(self, test_examples, test_latent_reps: torch.tensor):\n",
        "    H = self.corpus_latent_reps.cpu().numpy()\n",
        "    test_latent_reps_np = test_latent_reps.cpu().numpy()\n",
        "    n_test = test_latent_reps.shape[0]\n",
        "\n",
        "    all_weights_full = np.empty((n_test, self.corpus_size))\n",
        "\n",
        "    for i in range(n_test):\n",
        "      h = test_latent_reps_np[i]\n",
        "\n",
        "      size_corpus = H.shape[0]\n",
        "      X = np.vstack([H, h])\n",
        "      y = np.repeat([1,-1], [size_corpus, 1])\n",
        "      \n",
        "      svm = SVC(kernel=\"linear\", C=1000, tol=1e-5)\n",
        "      svm.fit(X, y)\n",
        "      \n",
        "      theta = svm.coef_\n",
        "      theta_0 = svm.intercept_\n",
        "      v = svm.support_vectors_[0]\n",
        "\n",
        "      # find projection of test point on opposite side of optimal separating hyperplane\n",
        "      d = theta.shape[1]\n",
        "      I = np.identity(d)\n",
        "      theta_sq = theta @ theta.T\n",
        "      v_0 = - theta_0 * theta / theta_sq\n",
        "\n",
        "      proj_plane = (I - (theta.T @ theta) / theta_sq) @ (v - v_0).T + v_0.T  # projection onto plane\n",
        "      proj_hull = 2 * proj_plane - v[:,None]  # projection onto convex hull\n",
        "      \n",
        "      # check it found a separating hyperplane\n",
        "      if not (y * (X @ theta.T + theta_0)[:,0] > 0).sum() == y.shape[0]:\n",
        "          raise ValueError('Not a separating hyperplane - test point lies inside the convex hull')\n",
        "      \n",
        "      # solve for the weights (note: LARS is <O(d^2 n) complexity)\n",
        "      num_weights = svm.support_vectors_[1:].T.shape[1]\n",
        "      lars = Lars(fit_intercept=False, normalize=False, n_nonzero_coefs=num_weights)\n",
        "      lars.fit(svm.support_vectors_[1:].T, proj_hull)\n",
        "      w = lars.coef_ # values of (non-zero) weights\n",
        "      w_idx = svm.support_[1:] # corresponding indices from the original corpus\n",
        "      all_weights = np.ones(size_corpus) * 2\n",
        "      np.add.at(all_weights, w_idx, w)\n",
        "      all_weights_full[i] = all_weights\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "    self.weights = torch.tensor(all_weights_full, device=device, dtype=torch.float32)\n",
        "    self.test_examples = test_examples\n",
        "    self.test_latent_reps = test_latent_reps\n",
        "    self.n_test = n_test\n",
        "    self.hist = None\n",
        "\n"
      ],
      "metadata": {
        "id": "0f4_gOM0Pbl0"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8pSpkq92dmWG"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters \n",
        "random_seed = 42\n",
        "cv = 0\n",
        "path = f'/content/Simplex/experiments/results/mnist/quality/model_cv{cv}.pth'\n",
        "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "corpus_size = 100\n",
        "test_size = 1\n",
        "n_epoch = 1000\n",
        "train_only = False\n",
        "reg_factor_init = 0.1\n",
        "reg_factor_final = 100\n",
        "n_keep = 5\n",
        "\n",
        "# main logic\n",
        "torch.random.manual_seed(random_seed + cv)\n",
        "explainers = []\n",
        "\n",
        "# Load model:\n",
        "classifier = MnistClassifier()\n",
        "classifier.load_state_dict(torch.load(path))\n",
        "classifier.to(device)\n",
        "classifier.eval()\n",
        "\n",
        "# Load data:\n",
        "corpus_loader = load_mnist(corpus_size, train=True)\n",
        "test_loader = load_mnist(test_size, train=train_only)\n",
        "corpus_examples = enumerate(corpus_loader)\n",
        "test_examples = enumerate(test_loader)\n",
        "batch_id_test, (test_data, test_targets) = next(test_examples)\n",
        "batch_id_corpus, (corpus_data, corpus_target) = next(corpus_examples)\n",
        "corpus_data = corpus_data.to(device).detach()\n",
        "test_data = test_data.to(device).detach()\n",
        "corpus_latent_reps = classifier.latent_representation(corpus_data).detach()\n",
        "corpus_probas = classifier.probabilities(corpus_data).detach()\n",
        "corpus_true_classes = torch.zeros(corpus_probas.shape, device=device)\n",
        "corpus_true_classes[torch.arange(corpus_size), corpus_target] = 1\n",
        "test_latent_reps = classifier.latent_representation(test_data).detach()\n",
        "\n",
        "# Fit SimplEx:\n",
        "reg_factor_scheduler = ExponentialScheduler(reg_factor_init, reg_factor_final, n_epoch)\n",
        "simplex = Simplex(corpus_examples=corpus_data,\n",
        "                  corpus_latent_reps=corpus_latent_reps)\n",
        "# simplex.fit(test_examples=test_data,\n",
        "#             test_latent_reps=test_latent_reps,\n",
        "#             n_epoch=n_epoch, reg_factor=reg_factor_init, n_keep=n_keep,\n",
        "#             reg_factor_scheduler=reg_factor_scheduler)\n",
        "simplex.fit_optimal(test_examples=test_data,\n",
        "            test_latent_reps=test_latent_reps)"
      ],
      "metadata": {
        "id": "BL4dFkLhIpaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35cb80df-11ab-45ea-9fd4-7901139c890e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.78718544e-01]\n",
            " [2.50573651e+00]\n",
            " [3.82174427e+00]\n",
            " [1.27837939e-03]\n",
            " [2.87064805e+00]\n",
            " [8.55420645e-01]\n",
            " [4.79595909e-01]\n",
            " [2.67114282e+00]\n",
            " [6.50174465e-01]\n",
            " [1.04379486e-02]\n",
            " [2.99004933e+00]\n",
            " [7.53328801e-01]\n",
            " [6.66864520e-01]\n",
            " [2.58058651e-01]\n",
            " [3.34648522e-01]\n",
            " [2.91951717e+00]\n",
            " [8.24605389e-01]\n",
            " [4.07658287e+00]\n",
            " [6.46723325e-01]\n",
            " [2.96743114e+00]\n",
            " [9.65946883e-01]\n",
            " [5.42170800e+00]\n",
            " [0.00000000e+00]\n",
            " [9.25315925e-01]\n",
            " [1.31696171e+00]\n",
            " [0.00000000e+00]\n",
            " [9.60201159e-01]\n",
            " [7.74020955e-01]\n",
            " [1.56602870e+00]\n",
            " [1.08899871e+00]\n",
            " [3.08982697e+00]\n",
            " [5.11372983e-01]\n",
            " [6.99154772e-01]\n",
            " [8.70832738e-01]\n",
            " [9.23201432e-01]\n",
            " [3.36467520e+00]\n",
            " [0.00000000e+00]\n",
            " [4.28504224e+00]\n",
            " [2.07263995e+00]\n",
            " [3.43680362e+00]\n",
            " [1.27231578e+00]\n",
            " [2.34498806e+00]\n",
            " [2.43040648e+00]\n",
            " [2.92707341e+00]\n",
            " [1.17990704e+00]\n",
            " [1.71747543e+00]\n",
            " [5.82182962e+00]\n",
            " [5.19734751e+00]\n",
            " [9.29072731e-01]\n",
            " [3.66710148e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simplex.latent_approx()"
      ],
      "metadata": {
        "id": "F0vb7KpNIpc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "647e342c-400c-460f-ace1-c0aca5e19c86"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[269.9886, 274.3505, 385.3306, 204.4398, 227.3402, 294.0723, 388.0108,\n",
              "         182.7255, 308.9944, 192.4235, 187.9205, 376.7293, 298.1154, 331.5479,\n",
              "         173.5808, 223.9094, 277.6101, 445.3861, 336.9451, 288.1857, 337.5789,\n",
              "         369.1134, 144.0418, 350.5494, 306.4515, 158.8003, 493.9688, 371.7798,\n",
              "         364.6609, 434.9784, 264.9983, 263.8355, 364.3654, 392.4078, 355.1985,\n",
              "         371.5394, 277.0637, 425.1588, 391.6181, 517.1254, 356.8463, 376.6756,\n",
              "         299.6625, 176.2598, 248.0298, 295.6180, 466.8196, 362.7202, 405.1676,\n",
              "         405.1920]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = simplex.weights @ simplex.corpus_latent_reps\n",
        "y.shape"
      ],
      "metadata": {
        "id": "I3-koIRJIpfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef4a38a-828f-45da-ffe7-987f722821b0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simplex.weights.shape"
      ],
      "metadata": {
        "id": "B9tfx7drIphv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba31360c-7dac-4fa0-a428-3c16914dde79"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "((x - y)**2).sum()**0.5"
      ],
      "metadata": {
        "id": "ZRmXQ98cIpkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4891f514-ae22-4964-9896-74b8cc0eb120"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.9417, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "a9XSBJWnIpmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68bc1a92-3c7f-4cdb-d13d-d25fb73ac262"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.7872e-01, 2.5057e+00, 3.8217e+00, 1.2784e-03, 2.8706e+00, 8.5542e-01,\n",
              "         4.7960e-01, 2.6711e+00, 6.5017e-01, 1.0438e-02, 2.9901e+00, 7.5333e-01,\n",
              "         6.6686e-01, 2.5806e-01, 3.3465e-01, 2.9195e+00, 8.2461e-01, 4.0766e+00,\n",
              "         6.4672e-01, 2.9674e+00, 9.6595e-01, 5.4217e+00, 0.0000e+00, 9.2532e-01,\n",
              "         1.3170e+00, 0.0000e+00, 9.6020e-01, 7.7402e-01, 1.5660e+00, 1.0890e+00,\n",
              "         3.0898e+00, 5.1137e-01, 6.9916e-01, 8.7083e-01, 9.2320e-01, 3.3647e+00,\n",
              "         0.0000e+00, 4.2850e+00, 2.0726e+00, 3.4368e+00, 1.2723e+00, 2.3450e+00,\n",
              "         2.4304e+00, 2.9271e+00, 1.1799e+00, 1.7175e+00, 5.8218e+00, 5.1973e+00,\n",
              "         9.2907e-01, 3.6671e+00]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "6.7872e-01"
      ],
      "metadata": {
        "id": "qeBAwyGTIpok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36690bb5-efdf-4b1f-f48e-db862112313c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.67872"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BI_dayYvIprB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AsRLwJkbIptE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3CjW7KaNIpvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # def latent_representation(self, x: torch.Tensor,\n",
        "    #                           test: bool = False) -> torch.Tensor:\n",
        "    #     x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    #     if test:\n",
        "    #       x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "    #     else:\n",
        "    #       x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    #     x = x.view(-1, 320)\n",
        "    #     x = F.relu(self.fc1(x))\n",
        "    #     if not test:\n",
        "    #       x = F.dropout(x, training=self.training)\n",
        "    #     return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_FlUb-AyzG5",
        "outputId": "474a052e-eaee-46f6-db2a-9b00d0db6d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Simplex/\n",
        "import explainers\n",
        "import models\n",
        "# from explainers.simplex import Simplex\n",
        "# from models.image_recognition import MnistClassifier\n",
        "# from experiments.mnist import load_mnist\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fll4BoQS05QY",
        "outputId": "3ab2588a-473f-44d3-f8d6-ae8bd47ceec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Simplex\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Simplex/\n",
        "from explainers.simplex import Simplex\n",
        "from models.image_recognition import MnistClassifier\n",
        "from experiments.mnist import load_mnist\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccTGQOxBm6go",
        "outputId": "2707f380-2e2b-4c4a-bc63-9fc7161ebd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Simplex\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, importlib\n",
        "%cd Simplex/\n",
        "importlib.reload(sys.modules['explainers.simplex'])\n",
        "from explainers.simplex import Simplex\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMMFXRfLCDbJ",
        "outputId": "5a7b007e-9184-4025-fac0-909ba63d6668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Simplex\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get a model\n",
        "model = MnistClassifier() # Model should have the BlackBox interface\n",
        "\n",
        "# Load corpus and test inputs\n",
        "corpus_loader = load_mnist(subset_size=100, train=True, batch_size=100) # MNIST train loader\n",
        "test_loader = load_mnist(subset_size=10, train=True, batch_size=10) # MNIST test loader\n",
        "corpus_inputs, _ = next(iter(corpus_loader)) # A tensor of corpus inputs\n",
        "test_inputs, _ = next(iter(test_loader)) # A set of inputs to explain\n",
        "\n",
        "# Compute the corpus and test latent representations\n",
        "corpus_latents = model.latent_representation(corpus_inputs).detach()\n",
        "test_latents = model.latent_representation(test_inputs).detach()\n",
        "\n",
        "# Initialize SimplEX, fit it on test examples\n",
        "simplex = Simplex(corpus_examples=corpus_inputs, \n",
        "                  corpus_latent_reps=corpus_latents)\n",
        "simplex.fit(test_examples=test_inputs, \n",
        "            test_latent_reps=test_latents,\n",
        "            reg_factor=0)\n",
        "\n",
        "# Get the weights of each corpus decomposition\n",
        "weights = simplex.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZhvn1tBn8rv",
        "outputId": "5b71c33b-d99c-4e66-8d56-45c5874c5d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight Fitting Epoch: 2000/10000 ; Error: 20.5 ; Regulator: 6.14 ; Reg Factor: 0\n",
            "Weight Fitting Epoch: 4000/10000 ; Error: 17.1 ; Regulator: 2.47 ; Reg Factor: 0\n",
            "Weight Fitting Epoch: 6000/10000 ; Error: 16.6 ; Regulator: 1.79 ; Reg Factor: 0\n",
            "Weight Fitting Epoch: 8000/10000 ; Error: 16.5 ; Regulator: 1.65 ; Reg Factor: 0\n",
            "Weight Fitting Epoch: 10000/10000 ; Error: 16.5 ; Regulator: 1.62 ; Reg Factor: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Compute the Integrated Jacobian for a particular example\n",
        "i = 4\n",
        "input_baseline = torch.zeros(corpus_inputs.shape) # Baseline tensor of the same shape as corpus_inputs\n",
        "simplex.jacobian_projection(test_id=i, model=model,\n",
        "                             input_baseline=input_baseline)\n",
        "\n",
        "result = simplex.decompose(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwYe1rrEoj8J",
        "outputId": "db4bcbf8-9083-459b-82b1-963f4f416a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor([ 3.4536e-01,  2.7351e-02,  2.3823e-01, -7.4672e-03,  4.3900e-01,\n",
            "        -5.6099e-02, -3.9818e-02,  2.2314e-03,  3.3941e-02,  8.5732e-05,\n",
            "         1.7575e-01,  3.7302e-05,  2.9429e-01,  3.2185e-02,  1.8232e-02,\n",
            "         8.2373e-01,  8.5893e-02,  1.9391e-01,  2.8152e-02,  2.5287e-01,\n",
            "         4.9622e-02,  2.2783e-02,  1.2279e-01,  1.8696e-01,  3.8638e-02,\n",
            "         6.5950e-03,  4.7221e-02,  6.2021e-02,  3.5906e-02,  3.6956e-07,\n",
            "         9.2338e-07, -5.0640e-02,  2.8502e-02, -2.4129e-02,  3.2652e-01,\n",
            "         7.8590e-02, -2.5083e-02,  1.1306e-02,  7.9015e-02,  0.0000e+00,\n",
            "         2.4351e-01,  2.7804e-01,  4.6262e-02,  1.2907e-01,  1.0201e-01,\n",
            "         2.9487e-02,  1.2219e-05,  1.5570e-04,  1.7108e-01,  1.6670e-03],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = 0\n",
        "w_c, x_c, proj_jacobian_c = result[c]"
      ],
      "metadata": {
        "id": "5PV44bBpqsNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpS4HBv4okAW",
        "outputId": "199306a8-7215-4285-f461-279382e207d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20396684"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_SYn0sKpBciG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}